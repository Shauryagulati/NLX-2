{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711bb1e3",
   "metadata": {},
   "source": [
    "Advanced RAG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f0713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models\n",
      "Loaded 150 queries\n",
      "\n",
      "Running both pipelines\n",
      "  Processed 5/150 queries\n",
      "  Processed 10/150 queries\n",
      "  Processed 15/150 queries\n",
      "  Processed 20/150 queries\n",
      "  Processed 25/150 queries\n",
      "  Processed 30/150 queries\n",
      "  Processed 35/150 queries\n",
      "  Processed 40/150 queries\n",
      "  Processed 45/150 queries\n",
      "  Processed 50/150 queries\n",
      "  Processed 55/150 queries\n",
      "  Processed 60/150 queries\n",
      "  Processed 65/150 queries\n",
      "  Processed 70/150 queries\n",
      "  Processed 75/150 queries\n",
      "  Processed 80/150 queries\n",
      "  Processed 85/150 queries\n",
      "  Processed 90/150 queries\n",
      "  Processed 95/150 queries\n",
      "  Processed 100/150 queries\n",
      "  Processed 105/150 queries\n",
      "  Processed 110/150 queries\n",
      "  Processed 115/150 queries\n",
      "  Processed 120/150 queries\n",
      "  Processed 125/150 queries\n",
      "  Processed 130/150 queries\n",
      "  Processed 135/150 queries\n",
      "  Processed 140/150 queries\n",
      "  Processed 145/150 queries\n",
      "  Processed 150/150 queries\n",
      "\n",
      "CGenerated 150 predictions per pipeline.\n",
      "\n",
      "Results\n",
      "| Pipeline                      |   Exact Match (%) |   Fuzzy Match (%) |   Avg F1 (%) |\n",
      "|:------------------------------|------------------:|------------------:|-------------:|\n",
      "| Naive RAG (Baseline)          |           44.6667 |           59.3333 |      56.5602 |\n",
      "| Advanced RAG (Rewrite+Rerank) |           46.6667 |           62      |      59.4995 |\n",
      "\n",
      "IMPROVEMENTS:\n",
      "Exact Match: +2.0 percentage points\n",
      "Fuzzy Match: +2.7 percentage points\n",
      "Average F1: +2.9 percentage points\n",
      "\n",
      "Advanced_rag_comparison.csv\n",
      "Saved advanced_rag_detailed_comparison.csv\n",
      "Summary\n",
      "\n",
      "Results:\n",
      "\n",
      "Naive RAG (Baseline):\n",
      "   - Exact Match: 44.7%\n",
      "   - Fuzzy Match: 59.3%\n",
      "   - Average F1: 56.6%\n",
      "\n",
      "Advanced RAG (Rewrite + Rerank):\n",
      "   - Exact Match: 46.7%\n",
      "   - Fuzzy Match: 62.0%\n",
      "   - Average F1: 59.5%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from pymilvus import MilvusClient\n",
    "from difflib import SequenceMatcher\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Config\n",
    "DB_NAME = \"rag_experiments_384d.db\"\n",
    "COLLECTION_NAME = 'rag_mini_384d'\n",
    "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "\n",
    "print(\"Loading models\")\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "llm_model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(llm_model_name)\n",
    "\n",
    "client = MilvusClient(DB_NAME)\n",
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "queries_df = pd.read_parquet(\n",
    "    \"hf://datasets/rag-datasets/rag-mini-wikipedia/data/test.parquet/part.0.parquet\"\n",
    ").head(150)\n",
    "\n",
    "print(f\"Loaded {len(queries_df)} queries\\n\")\n",
    "\n",
    "#Fuzzy Matching instead of Exact Matching\n",
    "def fuzzy_match(pred, truth):\n",
    "    \"\"\"Check if prediction is contained in truth or vice versa\"\"\"\n",
    "    pred_lower = pred.lower().strip()\n",
    "    truth_lower = truth.lower().strip()\n",
    "    \n",
    "    #Exact match\n",
    "    if pred_lower == truth_lower:\n",
    "        return 1.0\n",
    "    \n",
    "    #Substring match (answer contains ground truth or vice versa)\n",
    "    if pred_lower in truth_lower or truth_lower in pred_lower:\n",
    "        return 0.8\n",
    "    \n",
    "    #Sequence similarity\n",
    "    similarity = SequenceMatcher(None, pred_lower, truth_lower).ratio()\n",
    "    return similarity if similarity > 0.7 else 0.0\n",
    "\n",
    "def calculate_metrics(predictions, ground_truths):\n",
    "    \"\"\"Calculate multiple evaluation metrics\"\"\"\n",
    "    exact_match = 0\n",
    "    fuzzy_correct = 0\n",
    "    f1_scores = []\n",
    "    \n",
    "    for pred, truth in zip(predictions, ground_truths):\n",
    "        #Exact match\n",
    "        if pred.lower().strip() == truth.lower().strip():\n",
    "            exact_match += 1\n",
    "            fuzzy_correct += 1\n",
    "            f1_scores.append(1.0)\n",
    "        else:\n",
    "            #Fuzzy match\n",
    "            score = fuzzy_match(pred, truth)\n",
    "            if score >= 0.8:\n",
    "                fuzzy_correct += 1\n",
    "            f1_scores.append(score)\n",
    "    \n",
    "    return {\n",
    "        'exact_match': (exact_match / len(predictions)) * 100,\n",
    "        'fuzzy_match': (fuzzy_correct / len(predictions)) * 100,\n",
    "        'avg_f1': (sum(f1_scores) / len(f1_scores)) * 100\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#RAG function\n",
    "def create_persona_prompt(context, query):\n",
    "    return f\"You are an expert encyclopedia. Answer the question based on the context.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{query}\\n\\nAnswer:\"\n",
    "\n",
    "def generate_naive_rag(query, top_k=3):\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    search_results = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=[query_embedding],\n",
    "        limit=top_k,\n",
    "        output_fields=[\"passage\"]\n",
    "    )\n",
    "    contexts = [hit['entity']['passage'] for hit in search_results[0]]\n",
    "    context_str = \"\\n\".join(contexts)\n",
    "    prompt = create_persona_prompt(context_str, query)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).input_ids\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer, contexts\n",
    "\n",
    "def rewrite_query(query):\n",
    "    rewrite_prompt = f\"Rephrase this question 2 different ways:\\nQuestion: {query}\\nRephrasings:\"\n",
    "    input_ids = tokenizer(rewrite_prompt, return_tensors=\"pt\", truncation=True, max_length=512).input_ids\n",
    "    outputs = model.generate(input_ids, max_length=150)\n",
    "    rewritten = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    alternatives = [q.strip() for q in rewritten.split('\\n') if q.strip() and len(q.strip()) > 10]\n",
    "    return [query] + alternatives[:2]\n",
    "\n",
    "def rerank_passages(query, passages, top_k=3):\n",
    "    if len(passages) <= top_k:\n",
    "        return passages\n",
    "    pairs = [[query, passage] for passage in passages]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    reranked = sorted(zip(scores, passages), reverse=True)\n",
    "    return [passage for _, passage in reranked[:top_k]]\n",
    "\n",
    "def generate_advanced_rag(query, top_k=3):\n",
    "    queries = rewrite_query(query)\n",
    "    all_passages = []\n",
    "    for q in queries:\n",
    "        query_embedding = embedding_model.encode(q)\n",
    "        results = client.search(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            data=[query_embedding],\n",
    "            limit=10,\n",
    "            output_fields=[\"passage\"]\n",
    "        )\n",
    "        all_passages.extend([hit['entity']['passage'] for hit in results[0]])\n",
    "    unique_passages = list(dict.fromkeys(all_passages))\n",
    "    contexts = rerank_passages(query, unique_passages, top_k=top_k)\n",
    "    context_str = \"\\n\".join(contexts)\n",
    "    prompt = create_persona_prompt(context_str, query)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).input_ids\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer, contexts\n",
    "\n",
    "\n",
    "#Evaluation on 150 queries\n",
    "print(\"Running both pipelines\")\n",
    "\n",
    "naive_answers = []\n",
    "advanced_answers = []\n",
    "\n",
    "for i in range(len(queries_df)):\n",
    "    question = queries_df.iloc[i]['question']\n",
    "    \n",
    "    # Naive\n",
    "    n_ans, _ = generate_naive_rag(question, top_k=3)\n",
    "    naive_answers.append(n_ans)\n",
    "    \n",
    "    # Advanced\n",
    "    a_ans, _ = generate_advanced_rag(question, top_k=3)\n",
    "    advanced_answers.append(a_ans)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"  Processed {i+1}/150 queries\")\n",
    "\n",
    "print(f\"\\nCGenerated {len(naive_answers)} predictions per pipeline.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Evaluate\n",
    "ground_truths = queries_df['answer'].tolist()\n",
    "\n",
    "naive_metrics = calculate_metrics(naive_answers, ground_truths)\n",
    "advanced_metrics = calculate_metrics(advanced_answers, ground_truths)\n",
    "\n",
    "print(\"Results\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Pipeline': ['Naive RAG (Baseline)', 'Advanced RAG (Rewrite+Rerank)'],\n",
    "    'Exact Match (%)': [naive_metrics['exact_match'], advanced_metrics['exact_match']],\n",
    "    'Fuzzy Match (%)': [naive_metrics['fuzzy_match'], advanced_metrics['fuzzy_match']],\n",
    "    'Avg F1 (%)': [naive_metrics['avg_f1'], advanced_metrics['avg_f1']]\n",
    "})\n",
    "\n",
    "print(results_df.to_markdown(index=False))\n",
    "\n",
    "em_improvement = advanced_metrics['exact_match'] - naive_metrics['exact_match']\n",
    "fuzzy_improvement = advanced_metrics['fuzzy_match'] - naive_metrics['fuzzy_match']\n",
    "f1_improvement = advanced_metrics['avg_f1'] - naive_metrics['avg_f1']\n",
    "\n",
    "print(f\"\\nIMPROVEMENTS:\")\n",
    "print(f\"Exact Match: {em_improvement:+.1f} percentage points\")\n",
    "print(f\"Fuzzy Match: {fuzzy_improvement:+.1f} percentage points\")\n",
    "print(f\"Average F1: {f1_improvement:+.1f} percentage points\")\n",
    "\n",
    "\n",
    "\n",
    "# #Detailed Comparison\n",
    "# print(\"DETAILED ANSWER COMPARISON (First 10)\")\n",
    "\n",
    "# for i in range(10):\n",
    "#     gt = ground_truths[i]\n",
    "#     n_ans = naive_answers[i]\n",
    "#     a_ans = advanced_answers[i]\n",
    "    \n",
    "#     n_match = \"Right\" if n_ans.lower().strip() == gt.lower().strip() else \"Wrong\"\n",
    "#     a_match = \"Right\" if a_ans.lower().strip() == gt.lower().strip() else \"Wrong\"\n",
    "    \n",
    "#     print(f\"\\n[{i+1}] {queries_df.iloc[i]['question'][:60]}...\")\n",
    "#     print(f\"Ground Truth: '{gt}'\")\n",
    "#     print(f\"Naive:  '{n_ans}' {n_match}\")\n",
    "#     print(f\"Advanced: '{a_ans}' {a_match}\")\n",
    "\n",
    "\n",
    "#Save Results\n",
    "results_df.to_csv(\"advanced_rag_comparison.csv\", index=False)\n",
    "print(\"\\nAdvanced_rag_comparison.csv\")\n",
    "\n",
    "detailed = pd.DataFrame({\n",
    "    'question': queries_df['question'].tolist(),\n",
    "    'ground_truth': ground_truths,\n",
    "    'naive_answer': naive_answers,\n",
    "    'advanced_answer': advanced_answers,\n",
    "    'naive_exact': [n.lower().strip() == g.lower().strip() for n, g in zip(naive_answers, ground_truths)],\n",
    "    'advanced_exact': [a.lower().strip() == g.lower().strip() for a, g in zip(advanced_answers, ground_truths)]\n",
    "})\n",
    "detailed.to_csv(\"advanced_rag_detailed_comparison.csv\", index=False)\n",
    "print(\"Saved advanced_rag_detailed_comparison.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Report Summary\n",
    "print(\"Summary\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Results:\n",
    "\n",
    "Naive RAG (Baseline):\n",
    "   - Exact Match: {naive_metrics['exact_match']:.1f}%\n",
    "   - Fuzzy Match: {naive_metrics['fuzzy_match']:.1f}%\n",
    "   - Average F1: {naive_metrics['avg_f1']:.1f}%\n",
    "\n",
    "Advanced RAG (Rewrite + Rerank):\n",
    "   - Exact Match: {advanced_metrics['exact_match']:.1f}%\n",
    "   - Fuzzy Match: {advanced_metrics['fuzzy_match']:.1f}%\n",
    "   - Average F1: {advanced_metrics['avg_f1']:.1f}%\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fdce5",
   "metadata": {},
   "source": [
    "RAGAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key set: True\n",
      "Key starts with: sk-proj-5p...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "print(f\"API Key set: {bool(os.environ.get('OPENAI_API_KEY'))}\")\n",
    "print(f\"Key starts with: {os.environ.get('OPENAI_API_KEY', '')[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c3e776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing RAGAs\n",
      "RAGAs imported successfully!\n",
      "\n",
      "Loading models\n",
      "Loaded 150 test queries\n",
      "\n",
      "Initializing RAGAs with gpt-4o-mini\n",
      "RAGAs judge model ready!\n",
      "\n",
      "GENERATING PREDICTIONS FOR RAGAS EVALUATION\n",
      "  Generated 5/150 predictions\n",
      "  Generated 10/150 predictions\n",
      "  Generated 15/150 predictions\n",
      "  Generated 20/150 predictions\n",
      "  Generated 25/150 predictions\n",
      "  Generated 30/150 predictions\n",
      "  Generated 35/150 predictions\n",
      "  Generated 40/150 predictions\n",
      "  Generated 45/150 predictions\n",
      "  Generated 50/150 predictions\n",
      "  Generated 55/150 predictions\n",
      "  Generated 60/150 predictions\n",
      "  Generated 65/150 predictions\n",
      "  Generated 70/150 predictions\n",
      "  Generated 75/150 predictions\n",
      "  Generated 80/150 predictions\n",
      "  Generated 85/150 predictions\n",
      "  Generated 90/150 predictions\n",
      "  Generated 95/150 predictions\n",
      "  Generated 100/150 predictions\n",
      "  Generated 105/150 predictions\n",
      "  Generated 110/150 predictions\n",
      "  Generated 115/150 predictions\n",
      "  Generated 120/150 predictions\n",
      "  Generated 125/150 predictions\n",
      "  Generated 130/150 predictions\n",
      "  Generated 135/150 predictions\n",
      "  Generated 140/150 predictions\n",
      "  Generated 145/150 predictions\n",
      "  Generated 150/150 predictions\n",
      "\n",
      "Generated 150 predictions per pipeline.\n",
      "\n",
      "Preparing datasets for RAGAs evaluation\n",
      "Naive dataset: 150 samples\n",
      "Advanced dataset: 150 samples\n",
      "\n",
      "RUNNING RAGAS EVALUATION\n",
      "Using OpenAI gpt-4o-mini to judge the quality of RAG outputs.\n",
      "Evaluating Naive RAG (Baseline)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c10ddd31ff4ef5b9d645bf251b41ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[1]: IndexError(list index out of range)\n",
      "Exception raised in Job[9]: IndexError(list index out of range)\n",
      "Exception raised in Job[5]: IndexError(list index out of range)\n",
      "Exception raised in Job[13]: IndexError(list index out of range)\n",
      "Exception raised in Job[21]: IndexError(list index out of range)\n",
      "Exception raised in Job[17]: IndexError(list index out of range)\n",
      "Exception raised in Job[29]: IndexError(list index out of range)\n",
      "Exception raised in Job[37]: IndexError(list index out of range)\n",
      "Exception raised in Job[49]: IndexError(list index out of range)\n",
      "Exception raised in Job[61]: IndexError(list index out of range)\n",
      "Exception raised in Job[57]: IndexError(list index out of range)\n",
      "Exception raised in Job[65]: IndexError(list index out of range)\n",
      "Exception raised in Job[69]: IndexError(list index out of range)\n",
      "Exception raised in Job[73]: IndexError(list index out of range)\n",
      "Exception raised in Job[77]: IndexError(list index out of range)\n",
      "Exception raised in Job[81]: IndexError(list index out of range)\n",
      "Exception raised in Job[85]: IndexError(list index out of range)\n",
      "Exception raised in Job[97]: IndexError(list index out of range)\n",
      "Exception raised in Job[93]: IndexError(list index out of range)\n",
      "Exception raised in Job[101]: IndexError(list index out of range)\n",
      "Exception raised in Job[105]: IndexError(list index out of range)\n",
      "Exception raised in Job[109]: IndexError(list index out of range)\n",
      "Exception raised in Job[117]: IndexError(list index out of range)\n",
      "Exception raised in Job[121]: IndexError(list index out of range)\n",
      "Exception raised in Job[125]: IndexError(list index out of range)\n",
      "Exception raised in Job[129]: IndexError(list index out of range)\n",
      "Exception raised in Job[133]: IndexError(list index out of range)\n",
      "Exception raised in Job[149]: IndexError(list index out of range)\n",
      "Exception raised in Job[145]: IndexError(list index out of range)\n",
      "Exception raised in Job[153]: IndexError(list index out of range)\n",
      "Exception raised in Job[157]: IndexError(list index out of range)\n",
      "Exception raised in Job[161]: IndexError(list index out of range)\n",
      "Exception raised in Job[165]: IndexError(list index out of range)\n",
      "Exception raised in Job[169]: IndexError(list index out of range)\n",
      "Exception raised in Job[173]: IndexError(list index out of range)\n",
      "Exception raised in Job[185]: IndexError(list index out of range)\n",
      "Exception raised in Job[181]: IndexError(list index out of range)\n",
      "Exception raised in Job[177]: IndexError(list index out of range)\n",
      "Exception raised in Job[189]: IndexError(list index out of range)\n",
      "Exception raised in Job[193]: IndexError(list index out of range)\n",
      "Exception raised in Job[197]: IndexError(list index out of range)\n",
      "Exception raised in Job[201]: IndexError(list index out of range)\n",
      "Exception raised in Job[209]: IndexError(list index out of range)\n",
      "Exception raised in Job[213]: IndexError(list index out of range)\n",
      "Exception raised in Job[221]: IndexError(list index out of range)\n",
      "Exception raised in Job[225]: IndexError(list index out of range)\n",
      "Exception raised in Job[229]: IndexError(list index out of range)\n",
      "Exception raised in Job[237]: IndexError(list index out of range)\n",
      "Exception raised in Job[241]: IndexError(list index out of range)\n",
      "Exception raised in Job[249]: IndexError(list index out of range)\n",
      "Exception raised in Job[245]: IndexError(list index out of range)\n",
      "Exception raised in Job[261]: IndexError(list index out of range)\n",
      "Exception raised in Job[273]: IndexError(list index out of range)\n",
      "Exception raised in Job[277]: IndexError(list index out of range)\n",
      "Exception raised in Job[293]: IndexError(list index out of range)\n",
      "Exception raised in Job[297]: IndexError(list index out of range)\n",
      "Exception raised in Job[309]: IndexError(list index out of range)\n",
      "Exception raised in Job[313]: IndexError(list index out of range)\n",
      "Exception raised in Job[317]: IndexError(list index out of range)\n",
      "Exception raised in Job[325]: IndexError(list index out of range)\n",
      "Exception raised in Job[329]: IndexError(list index out of range)\n",
      "Exception raised in Job[337]: IndexError(list index out of range)\n",
      "Exception raised in Job[333]: IndexError(list index out of range)\n",
      "Exception raised in Job[353]: IndexError(list index out of range)\n",
      "Exception raised in Job[357]: IndexError(list index out of range)\n",
      "Exception raised in Job[361]: IndexError(list index out of range)\n",
      "Exception raised in Job[373]: IndexError(list index out of range)\n",
      "Exception raised in Job[377]: IndexError(list index out of range)\n",
      "Exception raised in Job[385]: IndexError(list index out of range)\n",
      "Exception raised in Job[381]: IndexError(list index out of range)\n",
      "Exception raised in Job[405]: IndexError(list index out of range)\n",
      "Exception raised in Job[409]: IndexError(list index out of range)\n",
      "Exception raised in Job[413]: IndexError(list index out of range)\n",
      "Exception raised in Job[425]: IndexError(list index out of range)\n",
      "Exception raised in Job[429]: IndexError(list index out of range)\n",
      "Exception raised in Job[445]: IndexError(list index out of range)\n",
      "Exception raised in Job[453]: IndexError(list index out of range)\n",
      "Exception raised in Job[457]: IndexError(list index out of range)\n",
      "Exception raised in Job[461]: IndexError(list index out of range)\n",
      "Exception raised in Job[469]: IndexError(list index out of range)\n",
      "Exception raised in Job[473]: IndexError(list index out of range)\n",
      "Exception raised in Job[477]: IndexError(list index out of range)\n",
      "Exception raised in Job[485]: IndexError(list index out of range)\n",
      "Exception raised in Job[489]: IndexError(list index out of range)\n",
      "Exception raised in Job[493]: IndexError(list index out of range)\n",
      "Exception raised in Job[497]: IndexError(list index out of range)\n",
      "Exception raised in Job[513]: IndexError(list index out of range)\n",
      "Exception raised in Job[517]: IndexError(list index out of range)\n",
      "Exception raised in Job[521]: IndexError(list index out of range)\n",
      "Exception raised in Job[533]: IndexError(list index out of range)\n",
      "Exception raised in Job[537]: IndexError(list index out of range)\n",
      "Exception raised in Job[553]: IndexError(list index out of range)\n",
      "Exception raised in Job[549]: IndexError(list index out of range)\n",
      "Exception raised in Job[545]: IndexError(list index out of range)\n",
      "Exception raised in Job[557]: IndexError(list index out of range)\n",
      "Exception raised in Job[561]: IndexError(list index out of range)\n",
      "Exception raised in Job[577]: IndexError(list index out of range)\n",
      "Exception raised in Job[589]: IndexError(list index out of range)\n",
      "Exception raised in Job[593]: IndexError(list index out of range)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Advanced RAG (Rewrite+Rerank)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985c1afc343c4e5fbec31d98d92ca8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[1]: IndexError(list index out of range)\n",
      "Exception raised in Job[13]: IndexError(list index out of range)\n",
      "Exception raised in Job[9]: IndexError(list index out of range)\n",
      "Exception raised in Job[5]: IndexError(list index out of range)\n",
      "Exception raised in Job[17]: IndexError(list index out of range)\n",
      "Exception raised in Job[25]: IndexError(list index out of range)\n",
      "Exception raised in Job[21]: IndexError(list index out of range)\n",
      "Exception raised in Job[37]: IndexError(list index out of range)\n",
      "Exception raised in Job[33]: IndexError(list index out of range)\n",
      "Exception raised in Job[41]: IndexError(list index out of range)\n",
      "Exception raised in Job[45]: IndexError(list index out of range)\n",
      "Exception raised in Job[49]: IndexError(list index out of range)\n",
      "Exception raised in Job[53]: IndexError(list index out of range)\n",
      "Exception raised in Job[57]: IndexError(list index out of range)\n",
      "Exception raised in Job[73]: IndexError(list index out of range)\n",
      "Exception raised in Job[77]: IndexError(list index out of range)\n",
      "Exception raised in Job[93]: IndexError(list index out of range)\n",
      "Exception raised in Job[89]: IndexError(list index out of range)\n",
      "Exception raised in Job[109]: IndexError(list index out of range)\n",
      "Exception raised in Job[113]: IndexError(list index out of range)\n",
      "Exception raised in Job[117]: IndexError(list index out of range)\n",
      "Exception raised in Job[125]: IndexError(list index out of range)\n",
      "Exception raised in Job[129]: IndexError(list index out of range)\n",
      "Exception raised in Job[133]: IndexError(list index out of range)\n",
      "Exception raised in Job[145]: IndexError(list index out of range)\n",
      "Exception raised in Job[149]: IndexError(list index out of range)\n",
      "Exception raised in Job[153]: IndexError(list index out of range)\n",
      "Exception raised in Job[157]: IndexError(list index out of range)\n",
      "Exception raised in Job[169]: IndexError(list index out of range)\n",
      "Exception raised in Job[173]: IndexError(list index out of range)\n",
      "Exception raised in Job[177]: IndexError(list index out of range)\n",
      "Exception raised in Job[193]: IndexError(list index out of range)\n",
      "Exception raised in Job[201]: IndexError(list index out of range)\n",
      "Exception raised in Job[221]: IndexError(list index out of range)\n",
      "Exception raised in Job[237]: IndexError(list index out of range)\n",
      "Exception raised in Job[241]: IndexError(list index out of range)\n",
      "Exception raised in Job[249]: IndexError(list index out of range)\n",
      "Exception raised in Job[261]: IndexError(list index out of range)\n",
      "Exception raised in Job[265]: IndexError(list index out of range)\n",
      "Exception raised in Job[269]: IndexError(list index out of range)\n",
      "Exception raised in Job[273]: IndexError(list index out of range)\n",
      "Exception raised in Job[277]: IndexError(list index out of range)\n",
      "Exception raised in Job[281]: IndexError(list index out of range)\n",
      "Exception raised in Job[297]: IndexError(list index out of range)\n",
      "Exception raised in Job[305]: IndexError(list index out of range)\n",
      "Exception raised in Job[313]: IndexError(list index out of range)\n",
      "Exception raised in Job[317]: IndexError(list index out of range)\n",
      "Exception raised in Job[329]: IndexError(list index out of range)\n",
      "Exception raised in Job[333]: IndexError(list index out of range)\n",
      "Exception raised in Job[337]: IndexError(list index out of range)\n",
      "Exception raised in Job[341]: IndexError(list index out of range)\n",
      "Exception raised in Job[345]: IndexError(list index out of range)\n",
      "Exception raised in Job[353]: IndexError(list index out of range)\n",
      "Exception raised in Job[349]: IndexError(list index out of range)\n",
      "Exception raised in Job[357]: IndexError(list index out of range)\n",
      "Exception raised in Job[361]: IndexError(list index out of range)\n",
      "Exception raised in Job[365]: IndexError(list index out of range)\n",
      "Exception raised in Job[377]: IndexError(list index out of range)\n",
      "Exception raised in Job[373]: IndexError(list index out of range)\n",
      "Exception raised in Job[389]: IndexError(list index out of range)\n",
      "Exception raised in Job[397]: IndexError(list index out of range)\n",
      "Exception raised in Job[401]: IndexError(list index out of range)\n",
      "Exception raised in Job[409]: IndexError(list index out of range)\n",
      "Exception raised in Job[413]: IndexError(list index out of range)\n",
      "Exception raised in Job[417]: IndexError(list index out of range)\n",
      "Exception raised in Job[421]: IndexError(list index out of range)\n",
      "Exception raised in Job[441]: IndexError(list index out of range)\n",
      "Exception raised in Job[437]: IndexError(list index out of range)\n",
      "Exception raised in Job[445]: IndexError(list index out of range)\n",
      "Exception raised in Job[453]: IndexError(list index out of range)\n",
      "Exception raised in Job[461]: IndexError(list index out of range)\n",
      "Exception raised in Job[469]: IndexError(list index out of range)\n",
      "Exception raised in Job[465]: IndexError(list index out of range)\n",
      "Exception raised in Job[473]: IndexError(list index out of range)\n",
      "Exception raised in Job[481]: IndexError(list index out of range)\n",
      "Exception raised in Job[485]: IndexError(list index out of range)\n",
      "Exception raised in Job[497]: IndexError(list index out of range)\n",
      "Exception raised in Job[501]: IndexError(list index out of range)\n",
      "Exception raised in Job[505]: IndexError(list index out of range)\n",
      "Exception raised in Job[509]: IndexError(list index out of range)\n",
      "Exception raised in Job[513]: IndexError(list index out of range)\n",
      "Exception raised in Job[525]: IndexError(list index out of range)\n",
      "Exception raised in Job[521]: IndexError(list index out of range)\n",
      "Exception raised in Job[533]: IndexError(list index out of range)\n",
      "Exception raised in Job[537]: IndexError(list index out of range)\n",
      "Exception raised in Job[545]: IndexError(list index out of range)\n",
      "Exception raised in Job[557]: IndexError(list index out of range)\n",
      "Exception raised in Job[565]: IndexError(list index out of range)\n",
      "Exception raised in Job[561]: IndexError(list index out of range)\n",
      "Exception raised in Job[569]: IndexError(list index out of range)\n",
      "Exception raised in Job[577]: IndexError(list index out of range)\n",
      "Exception raised in Job[581]: IndexError(list index out of range)\n",
      "Exception raised in Job[585]: IndexError(list index out of range)\n",
      "Exception raised in Job[589]: IndexError(list index out of range)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAGAs evaluation done\n",
      "\n",
      "RAGAS EVALUATION RESULTS\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert [list([0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, nan, nan, nan, nan, nan, nan, 0.790231405515927, nan, 0.7504596024364599, nan, 0.7436686867676713, 0.726065956526272, nan, 0.9390847505571212, nan, nan, nan, nan, nan, nan, nan, nan, 0.8092584301875235, nan, nan, nan, nan, nan, 0.703719808354991, nan, nan, nan, nan, nan, 0.7556624112350016, 0.9194750871444589, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.9292853286778119, nan, nan, 0.0, nan, nan, nan, 0.726841808433011, nan, nan, nan, nan, 0.7670868783182766, 0.8649944987272046, nan, 0.7409715575840807, 0.7582459694650537, nan, nan, 0.9999999999999996, 0.7685469841879057, 0.7559677223852882, nan, nan, 0.7679964351787575, 0.8280394397759703, nan, nan, nan, 0.9460970722032842, nan, nan, nan, nan, 0.7647869861120177, 0.7411100400487461, 0.7328823970774668, nan, nan, nan, 0.8324313619988138, 0.7682591745927082, nan, nan, nan, nan, 0.733340400387636, 0.0, 0.7448274706906067, 0.8035885798625167, nan, nan, nan, 0.7540554893474805, 0.0, nan, nan, 0.8778617585967566, 0.8080290900882118, 0.7961265124309943, nan, 0.7979426766389878, nan, nan, nan, 0.7645712991253117, nan, nan, nan, 0.0, nan, nan, nan, nan, 0.7643505189004799, 0.7835839424977179, 0.8143147077466034, nan, nan, nan, 0.0, 0.7816196609417391, nan, nan, 0.8136508012440276, nan, nan, nan, nan, nan, 0.8870379649364635, 0.7360329678023557, 0.0, nan, 0.7755542350754362, 0.7592308488103875, nan, nan, 0.0, 0.5833333333041666, 0.9999999999, 0.49999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.99999999995, 0.49999999995, 0.9999999999, 0.3333333333, 0.9999999999, 0.49999999995, 0.5833333333041666, 0.8333333332916666, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.9999999999, 0.9999999999666667, 0.49999999995, 0.9999999999, 0.99999999995, 0.0, 0.3333333333, 0.8333333332916666, 0.9999999999666667, 0.0, 0.9999999999, 0.0, 0.49999999995, 0.99999999995, 0.9999999999, 0.49999999995, 0.9999999999, 0.99999999995, 0.8333333332916666, 0.99999999995, 0.0, 0.49999999995, 0.0, 0.0, 0.3333333333, 0.49999999995, 0.9999999999, 0.99999999995, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.5833333333041666, 0.99999999995, 0.9999999999666667, 0.0, 0.0, 0.9999999999666667, 0.9999999999, 0.99999999995, 0.99999999995, 0.8333333332916666, 0.8333333332916666, 0.9999999999, 0.8333333332916666, 0.0, 0.99999999995, 0.99999999995, 0.99999999995, 0.9999999999666667, 0.99999999995, 0.99999999995, 0.9999999999666667, 0.49999999995, 0.9999999999, 0.3333333333, 0.9999999999, 0.0, 0.0, 0.99999999995, 0.9999999999, 0.9999999999, 0.8333333332916666, 0.99999999995, 0.9999999999, 0.9999999999, 0.0, 0.0, 0.9999999999, 0.49999999995, 0.0, 0.9999999999, 0.9999999999, 0.49999999995, 0.3333333333, 0.49999999995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49999999995, 0.0, 0.3333333333, 0.49999999995, 0.49999999995, 0.0, 0.9999999999, 0.9999999999, 0.8333333332916666, 0.0, 0.0, 0.49999999995, 0.0, 0.49999999995, 0.49999999995, 0.99999999995, 0.9999999999, 0.9999999999, 0.0, 0.3333333333, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999666667, 0.8333333332916666, 0.99999999995, 0.9999999999, 0.0, 0.9999999999, 0.0, 0.99999999995, 0.9999999999, 0.9999999999, 0.0, 0.0, 0.3333333333, 0.9999999999, 0.0, 0.99999999995, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.0, 0.49999999995, 0.3333333333, 0.9999999999, 0.99999999995, 0.99999999995, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n list([1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, nan, nan, nan, nan, nan, nan, nan, 0.8379166742872712, nan, nan, nan, nan, nan, nan, nan, 0.8926040363649793, 0.7444352103587205, 0.7539749817755698, nan, nan, 0.8961055324696265, 0.7289981644217085, nan, nan, 0.0, 0.7952564493906923, 0.7630672580459482, nan, nan, nan, 0.7928240981761444, nan, nan, nan, 0.7638844374706212, 0.7527254695451299, nan, nan, nan, nan, 0.806070617743562, 0.806845332748615, nan, nan, nan, 0.7299916110245647, 0.7240311716901834, 0.7500544520682663, nan, 0.0, nan, 0.7530855521563146, 0.7491680075226194, 0.7478956842528289, 0.0, nan, 0.8403994460614884, 0.7424326023228511, 0.7401133450336189, nan, nan, 0.9180463484299454, nan, 0.7670868783182766, 0.9204202145603658, nan, nan, nan, nan, nan, nan, 0.7724229264939374, 0.7570240897163054, 0.7318946491689681, nan, 0.7703183731448089, nan, 0.7849953178237253, nan, nan, 0.9496737028965653, 0.9477732896541319, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.7969693307792766, nan, nan, 0.7597844621104501, 0.0, nan, 0.7807415571493689, nan, nan, 0.7410679963907395, nan, nan, nan, nan, 0.7518902090685232, 0.779881094336433, 0.8778052594297933, nan, nan, nan, 0.780484669160851, nan, 0.7578349817443475, nan, nan, nan, nan, 0.7500572303737703, nan, nan, 0.8968622713536692, 0.748417615292456, nan, nan, nan, nan, nan, 0.8503178693757462, nan, nan, 0.7583090787338115, nan, nan, 0.7490051987722713, nan, 0.8307252994906489, 0.7552370780213926, nan, nan, nan, nan, 0.7460816469181258, nan, nan, nan, nan, 0.7439119525377144, 0.0, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.8333333332916666, 0.9999999999, 0.9999999999, 0.9999999999, 0.3333333333, 0.9999999999666667, 0.8333333332916666, 0.9999999999, 0.8333333332916666, 0.99999999995, 0.9999999999, 0.9999999999666667, 0.9999999999, 0.9999999999, 0.9999999999, 0.0, 0.9999999999666667, 0.8333333332916666, 0.9999999999666667, 0.0, 0.9999999999, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.8333333332916666, 0.0, 0.9999999999, 0.49999999995, 0.0, 0.3333333333, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.0, 0.0, 0.9999999999666667, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.8333333332916666, 0.9999999999, 0.9999999999666667, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.99999999995, 0.9999999999666667, 0.8333333332916666, 0.9999999999666667, 0.9999999999666667, 0.49999999995, 0.9999999999, 0.3333333333, 0.9999999999, 0.0, 0.0, 0.99999999995, 0.9999999999, 0.99999999995, 0.9999999999666667, 0.9999999999666667, 0.9999999999, 0.9999999999666667, 0.0, 0.0, 0.8333333332916666, 0.9999999999, 0.0, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999666667, 0.9999999999, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.99999999995, 0.8333333332916666, 0.9999999999, 0.9999999999, 0.49999999995, 0.3333333333, 0.9999999999, 0.0, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.0, 0.49999999995, 0.9999999999, 0.8333333332916666, 0.9999999999, 0.9999999999, 0.0, 0.8333333332916666, 0.9999999999, 0.9999999999, 0.9999999999666667, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.99999999995, 0.9999999999, 0.0, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.0, 0.99999999995, 0.9999999999, 0.0, 0.9999999999666667, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.99999999995, 0.99999999995, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0])] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 219\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAGAS EVALUATION RESULTS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m comparison \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaive RAG\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFaithfulness\u001b[39m\u001b[38;5;124m'\u001b[39m: naive_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaithfulness\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     }\n\u001b[1;32m    217\u001b[0m })\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m--> 219\u001b[0m comparison[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcomparison\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mprint\u001b[39m(comparison\u001b[38;5;241m.\u001b[39mto_markdown())\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m#Calculate improvements\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/frame.py:11720\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11712\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m  11713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11714\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11718\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11719\u001b[0m ):\n\u001b[0;32m> 11720\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[1;32m  11722\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/generic.py:12485\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12479\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12480\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12483\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12484\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12486\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  12487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/generic.py:12442\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12438\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12440\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  12444\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/frame.py:11589\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11585\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m  11587\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  11588\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 11589\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11590\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m  11591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/internals/managers.py:1519\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1517\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m-> 1519\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1520\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[1;32m   1522\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/internals/blocks.py:406\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 406\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    409\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/frame.py:11508\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  11506\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[1;32m  11507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m> 11508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    723\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pandas/core/nanops.py:1686\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1683\u001b[0m inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(x)\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1686\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1688\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mcomplex128)\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert [list([0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, nan, nan, nan, nan, nan, nan, 0.790231405515927, nan, 0.7504596024364599, nan, 0.7436686867676713, 0.726065956526272, nan, 0.9390847505571212, nan, nan, nan, nan, nan, nan, nan, nan, 0.8092584301875235, nan, nan, nan, nan, nan, 0.703719808354991, nan, nan, nan, nan, nan, 0.7556624112350016, 0.9194750871444589, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.9292853286778119, nan, nan, 0.0, nan, nan, nan, 0.726841808433011, nan, nan, nan, nan, 0.7670868783182766, 0.8649944987272046, nan, 0.7409715575840807, 0.7582459694650537, nan, nan, 0.9999999999999996, 0.7685469841879057, 0.7559677223852882, nan, nan, 0.7679964351787575, 0.8280394397759703, nan, nan, nan, 0.9460970722032842, nan, nan, nan, nan, 0.7647869861120177, 0.7411100400487461, 0.7328823970774668, nan, nan, nan, 0.8324313619988138, 0.7682591745927082, nan, nan, nan, nan, 0.733340400387636, 0.0, 0.7448274706906067, 0.8035885798625167, nan, nan, nan, 0.7540554893474805, 0.0, nan, nan, 0.8778617585967566, 0.8080290900882118, 0.7961265124309943, nan, 0.7979426766389878, nan, nan, nan, 0.7645712991253117, nan, nan, nan, 0.0, nan, nan, nan, nan, 0.7643505189004799, 0.7835839424977179, 0.8143147077466034, nan, nan, nan, 0.0, 0.7816196609417391, nan, nan, 0.8136508012440276, nan, nan, nan, nan, nan, 0.8870379649364635, 0.7360329678023557, 0.0, nan, 0.7755542350754362, 0.7592308488103875, nan, nan, 0.0, 0.5833333333041666, 0.9999999999, 0.49999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.99999999995, 0.49999999995, 0.9999999999, 0.3333333333, 0.9999999999, 0.49999999995, 0.5833333333041666, 0.8333333332916666, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.9999999999, 0.9999999999666667, 0.49999999995, 0.9999999999, 0.99999999995, 0.0, 0.3333333333, 0.8333333332916666, 0.9999999999666667, 0.0, 0.9999999999, 0.0, 0.49999999995, 0.99999999995, 0.9999999999, 0.49999999995, 0.9999999999, 0.99999999995, 0.8333333332916666, 0.99999999995, 0.0, 0.49999999995, 0.0, 0.0, 0.3333333333, 0.49999999995, 0.9999999999, 0.99999999995, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.5833333333041666, 0.99999999995, 0.9999999999666667, 0.0, 0.0, 0.9999999999666667, 0.9999999999, 0.99999999995, 0.99999999995, 0.8333333332916666, 0.8333333332916666, 0.9999999999, 0.8333333332916666, 0.0, 0.99999999995, 0.99999999995, 0.99999999995, 0.9999999999666667, 0.99999999995, 0.99999999995, 0.9999999999666667, 0.49999999995, 0.9999999999, 0.3333333333, 0.9999999999, 0.0, 0.0, 0.99999999995, 0.9999999999, 0.9999999999, 0.8333333332916666, 0.99999999995, 0.9999999999, 0.9999999999, 0.0, 0.0, 0.9999999999, 0.49999999995, 0.0, 0.9999999999, 0.9999999999, 0.49999999995, 0.3333333333, 0.49999999995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49999999995, 0.0, 0.3333333333, 0.49999999995, 0.49999999995, 0.0, 0.9999999999, 0.9999999999, 0.8333333332916666, 0.0, 0.0, 0.49999999995, 0.0, 0.49999999995, 0.49999999995, 0.99999999995, 0.9999999999, 0.9999999999, 0.0, 0.3333333333, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999666667, 0.8333333332916666, 0.99999999995, 0.9999999999, 0.0, 0.9999999999, 0.0, 0.99999999995, 0.9999999999, 0.9999999999, 0.0, 0.0, 0.3333333333, 0.9999999999, 0.0, 0.99999999995, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.0, 0.49999999995, 0.3333333333, 0.9999999999, 0.99999999995, 0.99999999995, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n list([1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, nan, nan, nan, nan, nan, nan, nan, 0.8379166742872712, nan, nan, nan, nan, nan, nan, nan, 0.8926040363649793, 0.7444352103587205, 0.7539749817755698, nan, nan, 0.8961055324696265, 0.7289981644217085, nan, nan, 0.0, 0.7952564493906923, 0.7630672580459482, nan, nan, nan, 0.7928240981761444, nan, nan, nan, 0.7638844374706212, 0.7527254695451299, nan, nan, nan, nan, 0.806070617743562, 0.806845332748615, nan, nan, nan, 0.7299916110245647, 0.7240311716901834, 0.7500544520682663, nan, 0.0, nan, 0.7530855521563146, 0.7491680075226194, 0.7478956842528289, 0.0, nan, 0.8403994460614884, 0.7424326023228511, 0.7401133450336189, nan, nan, 0.9180463484299454, nan, 0.7670868783182766, 0.9204202145603658, nan, nan, nan, nan, nan, nan, 0.7724229264939374, 0.7570240897163054, 0.7318946491689681, nan, 0.7703183731448089, nan, 0.7849953178237253, nan, nan, 0.9496737028965653, 0.9477732896541319, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.7969693307792766, nan, nan, 0.7597844621104501, 0.0, nan, 0.7807415571493689, nan, nan, 0.7410679963907395, nan, nan, nan, nan, 0.7518902090685232, 0.779881094336433, 0.8778052594297933, nan, nan, nan, 0.780484669160851, nan, 0.7578349817443475, nan, nan, nan, nan, 0.7500572303737703, nan, nan, 0.8968622713536692, 0.748417615292456, nan, nan, nan, nan, nan, 0.8503178693757462, nan, nan, 0.7583090787338115, nan, nan, 0.7490051987722713, nan, 0.8307252994906489, 0.7552370780213926, nan, nan, nan, nan, 0.7460816469181258, nan, nan, nan, nan, 0.7439119525377144, 0.0, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.8333333332916666, 0.9999999999, 0.9999999999, 0.9999999999, 0.3333333333, 0.9999999999666667, 0.8333333332916666, 0.9999999999, 0.8333333332916666, 0.99999999995, 0.9999999999, 0.9999999999666667, 0.9999999999, 0.9999999999, 0.9999999999, 0.0, 0.9999999999666667, 0.8333333332916666, 0.9999999999666667, 0.0, 0.9999999999, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.8333333332916666, 0.0, 0.9999999999, 0.49999999995, 0.0, 0.3333333333, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.0, 0.0, 0.9999999999666667, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.8333333332916666, 0.9999999999, 0.9999999999666667, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.99999999995, 0.9999999999666667, 0.8333333332916666, 0.9999999999666667, 0.9999999999666667, 0.49999999995, 0.9999999999, 0.3333333333, 0.9999999999, 0.0, 0.0, 0.99999999995, 0.9999999999, 0.99999999995, 0.9999999999666667, 0.9999999999666667, 0.9999999999, 0.9999999999666667, 0.0, 0.0, 0.8333333332916666, 0.9999999999, 0.0, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999666667, 0.9999999999, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.99999999995, 0.8333333332916666, 0.9999999999, 0.9999999999, 0.49999999995, 0.3333333333, 0.9999999999, 0.0, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.0, 0.49999999995, 0.9999999999, 0.8333333332916666, 0.9999999999, 0.9999999999, 0.0, 0.8333333332916666, 0.9999999999, 0.9999999999, 0.9999999999666667, 0.9999999999, 0.9999999999666667, 0.9999999999666667, 0.99999999995, 0.9999999999, 0.0, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.0, 0.99999999995, 0.9999999999, 0.0, 0.9999999999666667, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.99999999995, 0.9999999999, 0.9999999999, 0.99999999995, 0.99999999995, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0])] to numeric"
     ]
    }
   ],
   "source": [
    "#RAGAs Implementation\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from pymilvus import MilvusClient\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "print(\"Importing RAGAs\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall\n",
    ")\n",
    "\n",
    "print(\"RAGAs imported successfully!\\n\")\n",
    "\n",
    "#Load Models and Database\n",
    "DB_NAME = \"rag_experiments_384d.db\"\n",
    "COLLECTION_NAME = 'rag_mini_384d'\n",
    "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "\n",
    "print(\"Loading models\")\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "llm_model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(llm_model_name)\n",
    "\n",
    "client = MilvusClient(DB_NAME)\n",
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "#Taking 150 queries\n",
    "queries_df = pd.read_parquet(\n",
    "    \"hf://datasets/rag-datasets/rag-mini-wikipedia/data/test.parquet/part.0.parquet\"\n",
    ").head(150)\n",
    "\n",
    "print(f\"Loaded {len(queries_df)} test queries\\n\")\n",
    "\n",
    "\n",
    "#Initializing RAGAs\n",
    "print(\"Initializing RAGAs with gpt-4o-mini\")\n",
    "\n",
    "ragas_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0\n",
    ")\n",
    "print(\"RAGAs judge model ready!\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#RAGAs Pipeline Model\n",
    "def create_persona_prompt(context, query):\n",
    "    return f\"You are an expert encyclopedia. Answer the question based on the context.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{query}\\n\\nAnswer:\"\n",
    "\n",
    "def generate_naive_rag(query, top_k=3):\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    search_results = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=[query_embedding],\n",
    "        limit=top_k,\n",
    "        output_fields=[\"passage\"]\n",
    "    )\n",
    "    contexts = [hit['entity']['passage'] for hit in search_results[0]]\n",
    "    context_str = \"\\n\".join(contexts)\n",
    "    prompt = create_persona_prompt(context_str, query)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).input_ids\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer, contexts\n",
    "\n",
    "def rewrite_query(query):\n",
    "    rewrite_prompt = f\"Rephrase this question 2 different ways:\\nQuestion: {query}\\nRephrasings:\"\n",
    "    input_ids = tokenizer(rewrite_prompt, return_tensors=\"pt\", truncation=True, max_length=512).input_ids\n",
    "    outputs = model.generate(input_ids, max_length=150)\n",
    "    rewritten = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    alternatives = [q.strip() for q in rewritten.split('\\n') if q.strip() and len(q.strip()) > 10]\n",
    "    return [query] + alternatives[:2]\n",
    "\n",
    "def rerank_passages(query, passages, top_k=3):\n",
    "    if len(passages) <= top_k:\n",
    "        return passages\n",
    "    pairs = [[query, passage] for passage in passages]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    reranked = sorted(zip(scores, passages), reverse=True)\n",
    "    return [passage for _, passage in reranked[:top_k]]\n",
    "\n",
    "def generate_advanced_rag(query, top_k=3):\n",
    "    queries = rewrite_query(query)\n",
    "    all_passages = []\n",
    "    for q in queries:\n",
    "        query_embedding = embedding_model.encode(q)\n",
    "        results = client.search(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            data=[query_embedding],\n",
    "            limit=10,\n",
    "            output_fields=[\"passage\"]\n",
    "        )\n",
    "        all_passages.extend([hit['entity']['passage'] for hit in results[0]])\n",
    "    unique_passages = list(dict.fromkeys(all_passages))\n",
    "    contexts = rerank_passages(query, unique_passages, top_k=top_k)\n",
    "    context_str = \"\\n\".join(contexts)\n",
    "    prompt = create_persona_prompt(context_str, query)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).input_ids\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer, contexts\n",
    "\n",
    "\n",
    "\n",
    "#Generate Predictions for Both the Naive and Advanced\n",
    "print(\"GENERATING PREDICTIONS FOR RAGAS EVALUATION\")\n",
    "\n",
    "naive_answers = []\n",
    "naive_contexts = []\n",
    "advanced_answers = []\n",
    "advanced_contexts = []\n",
    "\n",
    "for i in range(len(queries_df)):\n",
    "    question = queries_df.iloc[i]['question']\n",
    "    \n",
    "    #Naive RAG\n",
    "    n_ans, n_ctx = generate_naive_rag(question, top_k=3)\n",
    "    naive_answers.append(n_ans)\n",
    "    naive_contexts.append(n_ctx)\n",
    "    \n",
    "    #Advanced RAG\n",
    "    a_ans, a_ctx = generate_advanced_rag(question, top_k=3)\n",
    "    advanced_answers.append(a_ans)\n",
    "    advanced_contexts.append(a_ctx)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"  Generated {i+1}/150 predictions\")\n",
    "\n",
    "print(f\"\\nGenerated {len(naive_answers)} predictions per pipeline.\\n\")\n",
    "\n",
    "\n",
    "#Preparing Dataset for RAGAs\n",
    "print(\"Preparing datasets for RAGAs evaluation\")\n",
    "\n",
    "\n",
    "base_data = {\n",
    "    'question': queries_df['question'].tolist(),\n",
    "    'ground_truth': queries_df['answer'].tolist()  # Note: 'ground_truth' not 'ground_truths'\n",
    "}\n",
    "\n",
    "naive_dataset = Dataset.from_dict({\n",
    "    **base_data,\n",
    "    'answer': naive_answers,\n",
    "    'contexts': naive_contexts\n",
    "})\n",
    "\n",
    "advanced_dataset = Dataset.from_dict({\n",
    "    **base_data,\n",
    "    'answer': advanced_answers,\n",
    "    'contexts': advanced_contexts\n",
    "})\n",
    "\n",
    "print(f\"Naive dataset: {len(naive_dataset)} samples\")\n",
    "print(f\"Advanced dataset: {len(advanced_dataset)} samples\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#RAGAs Evaluation\n",
    "print(\"RUNNING RAGAS EVALUATION\")\n",
    "print(\"Using OpenAI gpt-4o-mini to judge the quality of RAG outputs.\")\n",
    "\n",
    "#Metrics we want evaluation on\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall\n",
    "]\n",
    "\n",
    "print(\"Evaluating Naive RAG (Baseline)\")\n",
    "naive_results = evaluate(\n",
    "    naive_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=ragas_llm\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluating Advanced RAG (Rewrite+Rerank)\")\n",
    "advanced_results = evaluate(\n",
    "    advanced_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=ragas_llm\n",
    ")\n",
    "\n",
    "print(\"\\nRAGAs evaluation done\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Display Results\n",
    "print(\"RAGAS EVALUATION RESULTS\")\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Naive RAG': {\n",
    "        'Faithfulness': naive_results['faithfulness'],\n",
    "        'Answer Relevancy': naive_results['answer_relevancy'],\n",
    "        'Context Precision': naive_results['context_precision'],\n",
    "        'Context Recall': naive_results['context_recall']\n",
    "    },\n",
    "    'Advanced RAG': {\n",
    "        'Faithfulness': advanced_results['faithfulness'],\n",
    "        'Answer Relevancy': advanced_results['answer_relevancy'],\n",
    "        'Context Precision': advanced_results['context_precision'],\n",
    "        'Context Recall': advanced_results['context_recall']\n",
    "    }\n",
    "}).T\n",
    "\n",
    "comparison['Avg Score'] = comparison.mean(axis=1)\n",
    "print(comparison.to_markdown())\n",
    "\n",
    "#Calculate improvements\n",
    "print(\"IMPROVEMENTS (Advanced - Naive)\")\n",
    "\n",
    "improvements = {\n",
    "    'Faithfulness': advanced_results['faithfulness'] - naive_results['faithfulness'],\n",
    "    'Answer Relevancy': advanced_results['answer_relevancy'] - naive_results['answer_relevancy'],\n",
    "    'Context Precision': advanced_results['context_precision'] - naive_results['context_precision'],\n",
    "    'Context Recall': advanced_results['context_recall'] - naive_results['context_recall']\n",
    "}\n",
    "\n",
    "for metric, value in improvements.items():\n",
    "    print(f\"{metric:20s}: {value:+.4f}\")\n",
    "\n",
    "\n",
    "#Saving Results \n",
    "print(\"Saving results to CSV files\")\n",
    "comparison.to_csv(\"ragas_evaluation_comparison.csv\")\n",
    "print(\"Saved ragas_evaluation_comparison.csv\")\n",
    "\n",
    "#saved detailed per query result\n",
    "naive_df = naive_results.to_pandas()\n",
    "advanced_df = advanced_results.to_pandas()\n",
    "\n",
    "detailed = pd.DataFrame({\n",
    "    'question': queries_df['question'].tolist(),\n",
    "    'ground_truth': queries_df['answer'].tolist(),\n",
    "    'naive_answer': naive_answers,\n",
    "    'advanced_answer': advanced_answers,\n",
    "    'naive_faithfulness': naive_df['faithfulness'].tolist(),\n",
    "    'naive_answer_relevancy': naive_df['answer_relevancy'].tolist(),\n",
    "    'naive_context_precision': naive_df['context_precision'].tolist(),\n",
    "    'naive_context_recall': naive_df['context_recall'].tolist(),\n",
    "    'adv_faithfulness': advanced_df['faithfulness'].tolist(),\n",
    "    'adv_answer_relevancy': advanced_df['answer_relevancy'].tolist(),\n",
    "    'adv_context_precision': advanced_df['context_precision'].tolist(),\n",
    "    'adv_context_recall': advanced_df['context_recall'].tolist()\n",
    "})\n",
    "\n",
    "detailed.to_csv(\"ragas_detailed_per_query.csv\", index=False)\n",
    "print(\"Saved ragas_detailed_per_query.csv\")\n",
    "\n",
    "\n",
    "#Final Summary\n",
    "print(\"Final Summary\")\n",
    "\n",
    "print(f\"\"\"\n",
    "\n",
    "Naive RAG (Baseline):\n",
    "   Faithfulness:      {naive_results['faithfulness']:.4f}\n",
    "   Answer Relevancy:  {naive_results['answer_relevancy']:.4f}\n",
    "   Context Precision: {naive_results['context_precision']:.4f}\n",
    "   Context Recall:    {naive_results['context_recall']:.4f}\n",
    "   Average:           {comparison.loc['Naive RAG', 'Avg Score']:.4f}\n",
    "\n",
    "Advanced RAG (Query Rewriting + Reranking):\n",
    "   Faithfulness:      {advanced_results['faithfulness']:.4f}\n",
    "   Answer Relevancy:  {advanced_results['answer_relevancy']:.4f}\n",
    "   Context Precision: {advanced_results['context_precision']:.4f}\n",
    "   Context Recall:    {advanced_results['context_recall']:.4f}\n",
    "   Average:           {comparison.loc['Advanced RAG', 'Avg Score']:.4f}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "client.close()\n",
    "print(\"Evaluations done and Files saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a630f",
   "metadata": {},
   "source": [
    "Extracting and Clearning RAGAs Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a11cd151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting RAGAs results from your evaluation\n",
      "\n",
      "RAW RAGAS RESULTS (with NaN values)\n",
      "\n",
      "Naive RAG - Raw scores per query:\n",
      "  Faithfulness: [0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]... (showing first 10)\n",
      "  Answer Relevancy: [nan, nan, nan, nan, nan, nan, 0.790231405515927, nan, 0.7504596024364599, nan]...\n",
      "  Context Precision: [0.5833333333041666, 0.9999999999, 0.49999999995, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.9999999999, 0.99999999995, 0.49999999995]...\n",
      "  Context Recall: [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]...\n",
      "Cleaned RAGAs Results (NaN values removed)\n",
      "\n",
      "Successful evaluations:\n",
      "  Naive RAG: 150/150 queries\n",
      "  Advanced RAG: 150/150 queries\n",
      "\n",
      "Final RAGAs Comparison\n",
      "|              |   Faithfulness |   Answer Relevancy |   Context Precision |   Context Recall |\n",
      "|:-------------|---------------:|-------------------:|--------------------:|-----------------:|\n",
      "| Naive RAG    |      0.704444  |          0.686802  |            0.671667 |        0.6       |\n",
      "| Advanced RAG |      0.732222  |          0.719409  |            0.843333 |        0.633333  |\n",
      "| Improvement  |      0.0277778 |          0.0326076 |            0.171667 |        0.0333333 |\n",
      "\n",
      "DETAILED METRIC BREAKDOWN\n",
      "\n",
      "Faithfulness:\n",
      "  Naive:    0.7044\n",
      "  Advanced: 0.7322\n",
      "  Change:   +0.0278 (+2.8%) ↑ IMPROVED\n",
      "\n",
      "Answer Relevancy:\n",
      "  Naive:    0.6868\n",
      "  Advanced: 0.7194\n",
      "  Change:   +0.0326 (+3.3%) ↑ IMPROVED\n",
      "\n",
      "Context Precision:\n",
      "  Naive:    0.6717\n",
      "  Advanced: 0.8433\n",
      "  Change:   +0.1717 (+17.2%) ↑ IMPROVED\n",
      "\n",
      "Context Recall:\n",
      "  Naive:    0.6000\n",
      "  Advanced: 0.6333\n",
      "  Change:   +0.0333 (+3.3%) ↑ IMPROVED\n",
      "\n",
      "Saved ragas_final_comparison.csv\n",
      "Saved ragas_per_query_details.csv\n",
      "\n",
      "Summary\n",
      "\n",
      "RAGAS EVALUATION RESULTS\n",
      "\n",
      "EVALUATION SETUP:\n",
      "- Framework: RAGAs (Retrieval-Augmented Generation Assessment)\n",
      "- Judge Model: OpenAI gpt-4o-mini\n",
      "\n",
      "RAGAS METRICS:\n",
      "\n",
      "Naive RAG (Baseline):\n",
      "  Faithfulness:      0.7044\n",
      "  Answer Relevancy:  0.6868\n",
      "  Context Precision: 0.6717\n",
      "  Context Recall:    0.6000\n",
      "  Average Score:     0.6657\n",
      "\n",
      "Advanced RAG (Query Rewriting + Reranking):\n",
      "  Faithfulness:      0.7322\n",
      "  Answer Relevancy:  0.7194\n",
      "  Context Precision: 0.8433\n",
      "  Context Recall:    0.6333\n",
      "  Average Score:     0.7321\n",
      "\n",
      "Performance Change:\n",
      "  Overall: +0.0663 (+6.6%)\n",
      "\n",
      "\n",
      "\n",
      "All the results are extracted and saved\n",
      "  1. ragas_final_comparison.csv - Summary table\n",
      "  2. ragas_per_query_details.csv - Per-query breakdown\n"
     ]
    }
   ],
   "source": [
    "#Extracting and Cleaning Results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Extracting RAGAs results from your evaluation\\n\")\n",
    "\n",
    "#Naive results and advanced results are in the variables. \n",
    "\n",
    "#Handling the Data\n",
    "try:\n",
    "    naive_df = naive_results.to_pandas()\n",
    "    advanced_df = advanced_results.to_pandas()\n",
    "    \n",
    "    print(\"RAW RAGAS RESULTS (with NaN values)\")\n",
    "    print(f\"\\nNaive RAG - Raw scores per query:\")\n",
    "    print(f\"  Faithfulness: {naive_df['faithfulness'].tolist()[:10]}... (showing first 10)\")\n",
    "    print(f\"  Answer Relevancy: {naive_df['answer_relevancy'].tolist()[:10]}...\")\n",
    "    print(f\"  Context Precision: {naive_df['context_precision'].tolist()[:10]}...\")\n",
    "    print(f\"  Context Recall: {naive_df['context_recall'].tolist()[:10]}...\")\n",
    "    \n",
    "    print(\"Cleaned RAGAs Results (NaN values removed)\")\n",
    "    \n",
    "    naive_clean = {\n",
    "        'Faithfulness': naive_df['faithfulness'].dropna().mean(),\n",
    "        'Answer Relevancy': naive_df['answer_relevancy'].dropna().mean(),\n",
    "        'Context Precision': naive_df['context_precision'].dropna().mean(),\n",
    "        'Context Recall': naive_df['context_recall'].dropna().mean()\n",
    "    }\n",
    "    \n",
    "    advanced_clean = {\n",
    "        'Faithfulness': advanced_df['faithfulness'].dropna().mean(),\n",
    "        'Answer Relevancy': advanced_df['answer_relevancy'].dropna().mean(),\n",
    "        'Context Precision': advanced_df['context_precision'].dropna().mean(),\n",
    "        'Context Recall': advanced_df['context_recall'].dropna().mean()\n",
    "    }\n",
    "    \n",
    "    #Count successful evaluations\n",
    "    naive_success = naive_df['faithfulness'].notna().sum()\n",
    "    advanced_success = advanced_df['faithfulness'].notna().sum()\n",
    "    \n",
    "    print(f\"\\nSuccessful evaluations:\")\n",
    "    print(f\"  Naive RAG: {naive_success}/150 queries\")\n",
    "    print(f\"  Advanced RAG: {advanced_success}/150 queries\")\n",
    "    \n",
    "    #Create clean comparison\n",
    "    comparison = pd.DataFrame({\n",
    "        'Naive RAG': naive_clean,\n",
    "        'Advanced RAG': advanced_clean,\n",
    "        'Improvement': {\n",
    "            k: advanced_clean[k] - naive_clean[k] \n",
    "            for k in naive_clean.keys()\n",
    "        }\n",
    "    }).T\n",
    "\n",
    "\n",
    "    print(\"\\nFinal RAGAs Comparison\")\n",
    "    print(comparison.to_markdown())\n",
    "    \n",
    "    print(\"\\nDETAILED METRIC BREAKDOWN\")\n",
    "    \n",
    "    for metric in ['Faithfulness', 'Answer Relevancy', 'Context Precision', 'Context Recall']:\n",
    "        naive_val = naive_clean[metric]\n",
    "        adv_val = advanced_clean[metric]\n",
    "        diff = adv_val - naive_val\n",
    "        direction = \"↑ IMPROVED\" if diff > 0 else \"↓ DECREASED\" if diff < 0 else \"→ NO CHANGE\"\n",
    "        \n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Naive:    {naive_val:.4f}\")\n",
    "        print(f\"  Advanced: {adv_val:.4f}\")\n",
    "        print(f\"  Change:   {diff:+.4f} ({diff*100:+.1f}%) {direction}\")\n",
    "    \n",
    "    # Save results\n",
    "    comparison.to_csv(\"ragas_final_comparison.csv\")\n",
    "    print(\"\\nSaved ragas_final_comparison.csv\")\n",
    "    \n",
    "    # Save detailed per-query results\n",
    "    detailed = pd.DataFrame({\n",
    "        'question': queries_df['question'].tolist(),\n",
    "        'ground_truth': queries_df['answer'].tolist(),\n",
    "        'naive_faithfulness': naive_df['faithfulness'].tolist(),\n",
    "        'naive_answer_relevancy': naive_df['answer_relevancy'].tolist(),\n",
    "        'naive_context_precision': naive_df['context_precision'].tolist(),\n",
    "        'naive_context_recall': naive_df['context_recall'].tolist(),\n",
    "        'adv_faithfulness': advanced_df['faithfulness'].tolist(),\n",
    "        'adv_answer_relevancy': advanced_df['answer_relevancy'].tolist(),\n",
    "        'adv_context_precision': advanced_df['context_precision'].tolist(),\n",
    "        'adv_context_recall': advanced_df['context_recall'].tolist()\n",
    "    })\n",
    "    detailed.to_csv(\"ragas_per_query_details.csv\", index=False)\n",
    "    print(\"Saved ragas_per_query_details.csv\")\n",
    "    \n",
    "    # Generate assignment summary\n",
    "    print()\n",
    "    print(\"Summary\")\n",
    "    \n",
    "    avg_naive = np.mean(list(naive_clean.values()))\n",
    "    avg_advanced = np.mean(list(advanced_clean.values()))\n",
    "    \n",
    "    print(f\"\"\"\n",
    "RAGAS EVALUATION RESULTS\n",
    "\n",
    "EVALUATION SETUP:\n",
    "- Framework: RAGAs (Retrieval-Augmented Generation Assessment)\n",
    "- Judge Model: OpenAI gpt-4o-mini\n",
    "\n",
    "RAGAS METRICS:\n",
    "\n",
    "Naive RAG (Baseline):\n",
    "  Faithfulness:      {naive_clean['Faithfulness']:.4f}\n",
    "  Answer Relevancy:  {naive_clean['Answer Relevancy']:.4f}\n",
    "  Context Precision: {naive_clean['Context Precision']:.4f}\n",
    "  Context Recall:    {naive_clean['Context Recall']:.4f}\n",
    "  Average Score:     {avg_naive:.4f}\n",
    "\n",
    "Advanced RAG (Query Rewriting + Reranking):\n",
    "  Faithfulness:      {advanced_clean['Faithfulness']:.4f}\n",
    "  Answer Relevancy:  {advanced_clean['Answer Relevancy']:.4f}\n",
    "  Context Precision: {advanced_clean['Context Precision']:.4f}\n",
    "  Context Recall:    {advanced_clean['Context Recall']:.4f}\n",
    "  Average Score:     {avg_advanced:.4f}\n",
    "\n",
    "Performance Change:\n",
    "  Overall: {(avg_advanced - avg_naive):+.4f} ({(avg_advanced - avg_naive)*100:+.1f}%)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "    print(\"\\nAll the results are extracted and saved\")\n",
    "    print(\"  1. ragas_final_comparison.csv - Summary table\")\n",
    "    print(\"  2. ragas_per_query_details.csv - Per-query breakdown\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error extracting results: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
