{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8620d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76063ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Installing and importing libraries\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ares-ai 0.6.6 requires evaluate==0.4.2, but you have evaluate 0.4.6 which is incompatible.\n",
      "ares-ai 0.6.6 requires openai==1.14.2, but you have openai 1.109.1 which is incompatible.\n",
      "ares-ai 0.6.6 requires sentence-transformers<3.0.0,>=2.2.2, but you have sentence-transformers 5.1.1 which is incompatible.\n",
      "ares-ai 0.6.6 requires transformers==4.40.1, but you have transformers 4.56.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(\"Step 1: Installing and importing libraries\")\n",
    "!pip install -qU pymilvus milvus-lite ragas sentence-transformers transformers torch datasets pandas evaluate \"pymilvus[milvus_lite]\"\n",
    "!pip install -qU langchain # For the text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4726028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers, torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import evaluate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730e4fc",
   "metadata": {},
   "source": [
    "Run-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483bb780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up configuration\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSetting up configuration\")\n",
    "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "COLLECTION_NAME = 'rag_mini_384d'\n",
    "DB_NAME = \"rag_experiments_384d.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006a7471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and preparing data\n"
     ]
    }
   ],
   "source": [
    "#Data Loading\n",
    "print(\"\\nLoading and preparing data\")\n",
    "passages = pd.read_parquet(\"hf://datasets/rag-datasets/rag-mini-wikipedia/data/passages.parquet/part.0.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed09ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 3200 documents into 4430 chunks.\n"
     ]
    }
   ],
   "source": [
    "#Chunking the documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "chunks = []\n",
    "for index, row in passages.iterrows():\n",
    "    text_chunks = text_splitter.split_text(row['passage'])\n",
    "    for i, chunk in enumerate(text_chunks):\n",
    "        chunks.append({'id': f\"{row.name}_{i}\", 'passage': chunk})\n",
    "chunk_df = pd.DataFrame(chunks)\n",
    "print(f\"Split {len(passages)} documents into {len(chunk_df)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41df58d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f711cc8ee14bc795944b65f106d915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4430 embeddings of dimension 384.\n"
     ]
    }
   ],
   "source": [
    "#Embedding Generation\n",
    "print(\"\\nGenerating embeddings\")\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "embeddings = embedding_model.encode(chunk_df['passage'].tolist(), show_progress_bar=True)\n",
    "chunk_df['embedding'] = list(embeddings)\n",
    "EMBEDDING_DIM = embeddings.shape[1]\n",
    "print(f\"Generated {len(embeddings)} embeddings of dimension {EMBEDDING_DIM}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01e0393",
   "metadata": {},
   "source": [
    "Vector Database Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3e63a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nSetting up Milvus vector database\")\n",
    "# # Defining Schema\n",
    "# id_field = FieldSchema(name=\"id\", dtype=DataType.VARCHAR, is_primary=True, max_length=256)\n",
    "# passage_field = FieldSchema(name=\"passage\", dtype=DataType.VARCHAR, max_length=65535)\n",
    "# embedding_field = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIM)\n",
    "# schema = CollectionSchema(fields=[id_field, passage_field, embedding_field], description=\"RAG Wikipedia Collection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ea50b",
   "metadata": {},
   "source": [
    "Creating Client and Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83b44076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = MilvusClient(DB_NAME)\n",
    "# if client.has_collection(collection_name=COLLECTION_NAME):\n",
    "#     print(f\"Collection '{COLLECTION_NAME}' already exists. Dropping it.\")\n",
    "#     client.drop_collection(collection_name=COLLECTION_NAME)\n",
    "# client.create_collection(collection_name=COLLECTION_NAME, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fffd8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Inserting Data into Milvus\n",
    "# data_to_insert = chunk_df.to_dict(orient='records')\n",
    "# res = client.insert(collection_name=COLLECTION_NAME, data=data_to_insert)\n",
    "# print(f\"Inserted {res['insert_count']} entities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5fc17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating\n",
    "# index_params = client.prepare_index_params()\n",
    "# index_params.add_index(field_name=\"embedding\", index_type=\"AUTOINDEX\", metric_type=\"L2\")\n",
    "# client.create_index(collection_name=COLLECTION_NAME, index_params=index_params)\n",
    "# client.load_collection(collection_name=COLLECTION_NAME)\n",
    "# print(\"Milvus setup complete and collection is loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8953139",
   "metadata": {},
   "source": [
    "Connecting to Already created Database Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc29c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connecting to existing database\n",
      "Successfully connected to collection 'rag_mini_384d'.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConnecting to existing database\")\n",
    "client = MilvusClient(DB_NAME)\n",
    "if not client.has_collection(collection_name=COLLECTION_NAME):\n",
    "    raise ValueError(f\"Collection '{COLLECTION_NAME}' not found. Please run the `build_database.ipynb` notebook first.\")\n",
    "\n",
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "print(f\"Successfully connected to collection '{COLLECTION_NAME}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8946e2",
   "metadata": {},
   "source": [
    "RAG Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014adef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up RAG pipeline components\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSetting up RAG pipeline components\")\n",
    "#QA Dataset and Metric\n",
    "queries_df = pd.read_parquet(\"hf://datasets/rag-datasets/rag-mini-wikipedia/data/test.parquet/part.0.parquet\").head(25)\n",
    "squad_metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a485243",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(llm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19969bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Strategies\n",
    "def create_instruction_prompt(context, query): return f\"Context:\\n{context}\\n\\nQuestion:\\n{query}\\n\\nAnswer:\"\n",
    "def create_cot_prompt(context, query): return f\"Context:\\n{context}\\n\\nQuestion:\\n{query}\\n\\nAnswer: Let's think step by step.\"\n",
    "def create_persona_prompt(context, query): return f\"You are an expert encyclopedia. Answer the question based on the context.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{query}\\n\\nAnswer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8695f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG Function\n",
    "def generate_rag_response(query, prompt_strategy, top_k):\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    search_results = client.search(collection_name=COLLECTION_NAME, data=[query_embedding], limit=top_k, output_fields=[\"passage\"])\n",
    "    context = \"\\\\n\".join([hit['entity']['passage'] for hit in search_results[0]])\n",
    "    prompt = prompt_strategy(context, query)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d620aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing evaluation loop\n",
      "--- Running: top_k=1, prompt='Instruction' ---\n",
      "--- Running: top_k=1, prompt='Chain-of-Thought' ---\n",
      "--- Running: top_k=1, prompt='Persona' ---\n",
      "--- Running: top_k=3, prompt='Instruction' ---\n",
      "--- Running: top_k=3, prompt='Chain-of-Thought' ---\n",
      "--- Running: top_k=3, prompt='Persona' ---\n",
      "--- Running: top_k=5, prompt='Instruction' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running: top_k=5, prompt='Chain-of-Thought' ---\n",
      "--- Running: top_k=5, prompt='Persona' ---\n"
     ]
    }
   ],
   "source": [
    "#Evaluation Function\n",
    "print(\"\\nExecuting evaluation loop\")\n",
    "results = []\n",
    "top_k_options = [1, 3, 5]\n",
    "prompt_strategies = {\n",
    "    \"Instruction\": create_instruction_prompt,\n",
    "    \"Chain-of-Thought\": create_cot_prompt,\n",
    "    \"Persona\": create_persona_prompt,\n",
    "}\n",
    "\n",
    "for k in top_k_options:\n",
    "    for name, func in prompt_strategies.items():\n",
    "        print(f\"--- Running: top_k={k}, prompt='{name}' ---\")\n",
    "        predictions_text = [generate_rag_response(q, func, k) for q in queries_df['question']]\n",
    "        predictions = [{'prediction_text': p, 'id': str(i)} for i, p in enumerate(predictions_text)]\n",
    "        references = [{'answers': {'text': [gt], 'answer_start': [0]}, 'id': str(i)} for i, gt in enumerate(queries_df['answer'])]\n",
    "        metrics = squad_metric.compute(predictions=predictions, references=references)\n",
    "        results.append({\n",
    "            \"Embedding Model\": EMBEDDING_MODEL_NAME,\n",
    "            \"Embedding Size\": EMBEDDING_DIM,\n",
    "            \"Prompt Strategy\": name,\n",
    "            \"Top K\": k,\n",
    "            \"Exact Match\": metrics['exact_match'],\n",
    "            \"F1 Score\": metrics['f1']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5900b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying results and cleaning up\n",
      "\n",
      "\n",
      "--- FINAL RESULTS ---\n",
      "| Embedding Model   |   Embedding Size | Prompt Strategy   |   Top K |   Exact Match |   F1 Score |\n",
      "|:------------------|-----------------:|:------------------|--------:|--------------:|-----------:|\n",
      "| all-MiniLM-L6-v2  |              384 | Instruction       |       1 |            52 |   61.7734  |\n",
      "| all-MiniLM-L6-v2  |              384 | Chain-of-Thought  |       1 |             0 |   11.9091  |\n",
      "| all-MiniLM-L6-v2  |              384 | Persona           |       1 |            56 |   63.7128  |\n",
      "| all-MiniLM-L6-v2  |              384 | Instruction       |       3 |            68 |   74.3795  |\n",
      "| all-MiniLM-L6-v2  |              384 | Chain-of-Thought  |       3 |             0 |   11.2226  |\n",
      "| all-MiniLM-L6-v2  |              384 | Persona           |       3 |            64 |   69.0462  |\n",
      "| all-MiniLM-L6-v2  |              384 | Instruction       |       5 |            68 |   77.0462  |\n",
      "| all-MiniLM-L6-v2  |              384 | Chain-of-Thought  |       5 |             0 |    9.88396 |\n",
      "| all-MiniLM-L6-v2  |              384 | Persona           |       5 |            68 |   75.7128  |\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDisplaying results and cleaning up\")\n",
    "client.close()\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\\n--- FINAL RESULTS ---\")\n",
    "print(results_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e008578",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"runs/Assignment2_384d_results.csv\", index=False)\n",
    "with open(\"runs/Assignment2_384d_results.md\",\"w\") as f:\n",
    "    f.write(results_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dc9eae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "THE QUERY\n",
      "'Was Abraham Lincoln the sixteenth President of the United States?'\n",
      "\n",
      "GROUND TRUTH ANSWER:\n",
      "'yes'\n",
      "\n",
      "RETRIEVED CONTEXT (Top 3 Chunks)\n",
      "\n",
      "[CHUNK 1]:\n",
      "\"Young Abraham Lincoln\"\n",
      "\n",
      "[CHUNK 2]:\n",
      "\"Abraham Lincoln (February 12, 1809 â April 15, 1865) was the sixteenth President of the United States, serving from March 4, 1861 until his assassination. As an outspoken opponent of the expansion of slavery in the United States, \"[I]n his short autobiography written for the 1860 presidential campaign, Lincoln would describe his protest in the Illinois legislature as one that 'briefly defined his position on the slavery question, and so far as it goes, it was then the same that it is now.\" This was in\"\n",
      "\n",
      "[CHUNK 3]:\n",
      "\"On November 6, 1860, Lincoln was elected as the 16th President of the United States, beating Democrat Stephen A. Douglas, John C. Breckinridge of the Southern Democrats, and John Bell of the new Constitutional Union Party. He was the first Republican president, winning entirely on the strength of his support in the North: he was not even on the ballot in nine states in the South, and won only 2 of 996 counties in the other Southern states. Lincoln gained 1,865,908 votes (39.9% of the total), for 180\"\n",
      "\n",
      "FINAL GENERATED ANSWER\n",
      "'yes'\n"
     ]
    }
   ],
   "source": [
    "def show_single_query_breakdown(index_to_test):\n",
    "\n",
    "    client = MilvusClient(DB_NAME)\n",
    "    client.load_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "    question = queries_df.iloc[index_to_test]['question']\n",
    "    ground_truth = queries_df.iloc[index_to_test]['answer']\n",
    "    top_k = 3\n",
    "    \n",
    "    def create_persona_prompt(context, query):\n",
    "        return f\"You are an expert encyclopedia. Answer the question based on the context.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{query}\\n\\nAnswer:\"\n",
    "\n",
    "    print(f\"\\nTHE QUERY\\n'{question}'\")\n",
    "    print(f\"\\nGROUND TRUTH ANSWER:\\n'{ground_truth}'\")\n",
    "\n",
    "    #Retrieval Step\n",
    "    query_embedding = embedding_model.encode(question)\n",
    "    search_results = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=[query_embedding],\n",
    "        limit=top_k,\n",
    "        output_fields=[\"passage\"]\n",
    "    )\n",
    "    \n",
    "    retrieved_chunks = [hit['entity']['passage'] for hit in search_results[0]]\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "    \n",
    "    print(f\"\\nRETRIEVED CONTEXT (Top {top_k} Chunks)\")\n",
    "    for i, chunk in enumerate(retrieved_chunks):\n",
    "        print(f\"\\n[CHUNK {i+1}]:\\n\\\"{chunk}\\\"\")\n",
    "\n",
    "    prompt = create_persona_prompt(context, question)\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    generated_answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\nFINAL GENERATED ANSWER\")\n",
    "    print(f\"'{generated_answer}'\")\n",
    "\n",
    "\n",
    "show_single_query_breakdown(index_to_test=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
